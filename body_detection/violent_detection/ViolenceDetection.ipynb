{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gmm_grupinis_darbas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dat8v3oHMju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62031a4-5d05-4d79-c1a7-b32aac494ff4"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASNYUVHCuwFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4e6dcc-5dad-4e4b-d335-58288b66e8ad"
      },
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPQ5feZ3zwzB"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/GMM_group/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/GMM_group/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HLXWv4hzDSH"
      },
      "source": [
        "def crop_center_square(frame):\n",
        "        y, x = frame.shape[0:2]\n",
        "        min_dim = min(y, x)\n",
        "        start_x = (x // 2) - (min_dim // 2)\n",
        "        start_y = (y // 2) - (min_dim // 2)\n",
        "        return frame[start_y : start_y+min_dim, start_x : start_x+min_dim]\n",
        "\n",
        "def load_video(path, max_frames=0):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, (224,224))\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DAc3uQmsyGH"
      },
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = keras.applications.ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(224, 224, 3))\n",
        "    inputs = keras.Input((224, 224, 3))\n",
        "    return keras.Model(inputs, cnn_model(keras.applications.resnet50.preprocess_input(inputs)), name=\"cnn_model\")\n",
        "\n",
        "cnn_model = build_cnn_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_WHgBm6VWt6"
      },
      "source": [
        "label_processor = keras.layers.experimental.preprocessing.StringLookup(\n",
        "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",
        ")\n",
        "print(label_processor.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E_zksdrZ2AZ"
      },
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"video_name\"].values.tolist()\n",
        "    labels = df[\"tag\"].values\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "    \n",
        "    frame_masks = np.zeros(shape=(num_samples, 60), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(num_samples, 60, 2048),\n",
        "                                dtype=\"float32\")\n",
        "    \n",
        "    for idx, path in enumerate(video_paths):\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "        \n",
        "        temp_frame_mask = np.zeros(shape=(1, 60, ), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(shape=(1, 60, 2048),\n",
        "                                dtype=\"float32\")\n",
        "        \n",
        "        for i, batch in enumerate(frames):  \n",
        "            video_length = batch.shape[0]\n",
        "            length = min(60, video_length)  \n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = cnn_model.predict(batch[None, j, :])  \n",
        "            temp_frame_mask[i, :length] = 1\n",
        "\n",
        "        frame_features[idx, ] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx, ] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWBXUZaNeK9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0705e186-7992-413b-9520-6e83e5678310"
      },
      "source": [
        "train_data, train_labels = prepare_all_videos(train_df, \"/content/drive/MyDrive/GMM_group/train\")\n",
        "test_data, test_labels = prepare_all_videos(test_df, \"/content/drive/MyDrive/GMM_group/test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame features in train set: (280, 60, 2048)\n",
            "Frame masks in train set: (280, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIuAlLO-jQpy"
      },
      "source": [
        "def get_rnn_model(): \n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((60, 2048))\n",
        "    mask_input = keras.Input((60,), dtype=\"bool\")\n",
        "\n",
        "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
        "    x = keras.layers.GRU(8)(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"])\n",
        "    return rnn_model\n",
        "\n",
        "def train_and_test_rnn_model():\n",
        "    rnn_model = get_rnn_model()\n",
        "    history = rnn_model.fit([train_data[0], train_data[1]], train_labels,\n",
        "        validation_split=0,\n",
        "        epochs=20)\n",
        "    \n",
        "    _, accuracy = rnn_model.evaluate([train_data[0], train_data[1]], train_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, rnn_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw7QW9Bvu_yG"
      },
      "source": [
        "_, rnn_model = train_and_test_rnn_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv26A9q2k3dF"
      },
      "source": [
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, 60, ), dtype=\"bool\")\n",
        "    frame_featutes = np.zeros(shape=(1, 60, 2048),\n",
        "                            dtype=\"float32\")\n",
        "    \n",
        "    for i, batch in enumerate(frames):  \n",
        "        video_length = batch.shape[1]\n",
        "        length = min(60, video_length)  \n",
        "        for j in range(length):\n",
        "            frame_featutes[i, j, :] = cnn_model.predict(batch[None, j, :])  \n",
        "        frame_mask[i, :length] = 1\n",
        "\n",
        "    return frame_featutes, frame_mask\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(os.path.join(\"test\", path))\n",
        "    print(frames.shape)\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = rnn_model.predict([frame_features, frame_mask])[0]\n",
        "    \n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "def to_gif(images):\n",
        "    converted_images = images.astype(np.uint8)\n",
        "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
        "    return embed.embed_file(\"animation.gif\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiw8eSaalzK3"
      },
      "source": [
        "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "test_frames = sequence_prediction(f'/content/drive/MyDrive/GMM_group/test/{test_video}')\n",
        "to_gif(test_frames[:60])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}